{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查 DataFrame 空缺值的狀態\n",
    "def na_check(df_data):\n",
    "    data_na = (df_data.isnull().sum() / len(df_data)) * 100\n",
    "    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "    display(missing_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "df_train = pd.read_csv(data_path + 'train_data.csv')\n",
    "df_test = pd.read_csv(data_path + 'test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bonus', 'deferral_payments', 'deferred_income', 'director_fees',\n",
       "       'email_address', 'exercised_stock_options', 'expenses', 'from_messages',\n",
       "       'from_poi_to_this_person', 'from_this_person_to_poi', 'loan_advances',\n",
       "       'long_term_incentive', 'other', 'restricted_stock',\n",
       "       'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi',\n",
       "       'to_messages', 'total_payments', 'total_stock_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y = df_train['poi']\n",
    "ids_train = df_train['name']\n",
    "ids = df_test['name']\n",
    "df_train = df_train.drop(['name', 'poi'] , axis=1)\n",
    "df_test = df_test.drop(['name'] , axis=1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "var_df_columns = df.columns\n",
    "var_df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df_dtypes = df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#薪水\n",
    "var_salary = ['salary']\n",
    "#獎金\n",
    "var_bonus = ['bonus']\n",
    "#業務報銷\n",
    "var_business_expenses_group = ['long_term_incentive','deferred_income','loan_advances'\n",
    "        ,'deferral_payments','other','expenses']\n",
    "#董事费\n",
    "var_9 = ['director_fees']\n",
    "#股權\n",
    "var_10_11_12 = ['exercised_stock_options','restricted_stock','restricted_stock_deferred']\n",
    "#股權 total\n",
    "var_total_stock_value = ['total_stock_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = df.copy()\n",
    "df_cp = df_cp.drop(['email_address'] , axis=1)\n",
    "df_cp = df_cp.drop(var_10_11_12 , axis=1)\n",
    "df_cp[var_total_stock_value] = df[var_total_stock_value].fillna(0)\n",
    "df_cp[var_salary] = df[var_salary].fillna(df_cp[var_salary].median())\n",
    "df_cp[var_bonus] = df[var_bonus].fillna(df_cp[var_bonus].median())\n",
    "df_cp['business_expenses_total']=np.zeros([146])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in var_business_expenses_group:\n",
    "    df_cp[col] = df_cp[col].fillna(0)\n",
    "    df_cp['business_expenses_total'] = df_cp['business_expenses_total'] + df_cp[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = df_cp.drop(var_business_expenses_group , axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_other in df_cp.columns:\n",
    "    df_cp[col_other] = df_cp[col_other].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "na_check(df_cp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料最大最小化\n",
    "df_cp = MinMaxScaler().fit_transform(df_cp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將前述轉換完畢資料 df , 重新切成 train_X, test_X\n",
    "train_num = train_Y.shape[0]\n",
    "train_X = df_cp[:train_num]\n",
    "test_X = df_cp[train_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用三種模型 : 邏輯斯迴歸 / 梯度提升機 / 隨機森林, 參數使用 Random Search 尋找\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "lr = LogisticRegression(tol=0.001, penalty='l2', fit_intercept=True, C=1.0)\n",
    "gdbt = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, max_features=11,\n",
    "                                  max_depth=6, learning_rate=0.03)\n",
    "rf = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=6, bootstrap=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線性迴歸預測檔 (結果有部分隨機, 請以 Kaggle 計算的得分為準, 以下模型同理)\n",
    "lr.fit(train_X, train_Y)\n",
    "lr_pred = lr.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': ids, 'poi': lr_pred})\n",
    "\n",
    "#sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('test_2_linear.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt.fit(train_X, train_Y)\n",
    "gdbt_pred = gdbt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': ids, 'poi': gdbt_pred})\n",
    "#sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('test_2_gdbt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機森林預測檔\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = rf.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': ids, 'poi': rf_pred})\n",
    "#sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('test_2_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "meta_estimator = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, \n",
    "                                           max_features='sqrt', max_depth=6, learning_rate=0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = StackingClassifier(classifiers=[gdbt, rf, lr],meta_classifier=meta_estimator)\n",
    "stacking.fit(train_X, train_Y)\n",
    "stacking_pred = stacking.predict(test_X)\n",
    "sub = pd.DataFrame({'name': ids, 'poi': stacking_pred})\n",
    "sub['poi'] = sub['poi'].map(lambda x:0.99 if x==True else 0.0) \n",
    "sub.to_csv('test_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.03,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=11,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=250,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=0.75, tol=100,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid=False, n_jobs=None,\n",
       "             param_grid={'max_depth': range(3, 14, 2),\n",
       "                         'min_samples_split': range(100, 801, 200)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test1 = {'n_estimators':range(20,300,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(tol=100, subsample=0.75, max_features=11,\n",
    "                                  max_depth=6, learning_rate=0.03),param_grid = param_test1, scoring='roc_auc',iid=False,cv=5)\n",
    "\n",
    "gsearch1.fit(train_X,train_Y)\n",
    "#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "param_test2 = {'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(tol=100, subsample=0.75, max_features=11,\n",
    "                                  max_depth=3,learning_rate=0.03,min_samples_split=2,n_estimators=250),param_grid = param_test2, scoring='roc_auc',iid=False,cv=5)\n",
    "\n",
    "gsearch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gdbt2\n",
    "gdbt2 = GradientBoostingClassifier(tol=100, subsample=0.75, max_features=11,\n",
    "                                  max_depth=3,learning_rate=0.03,min_samples_split=2,n_estimators=250)\n",
    "\n",
    "gdbt2.fit(train_X, train_Y)\n",
    "gdbt_pred2 = gdbt2.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'name': ids, 'poi': gdbt_pred2})\n",
    "#sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('test_gdbt2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
