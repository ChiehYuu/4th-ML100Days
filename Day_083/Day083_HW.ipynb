{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 試比較有 BN 在 Batch_size = 2, 16, 32, 128, 256 下的差異\n",
    "2. 請嘗試將 BN 放在 Activation 之前，並比較訓練結果\n",
    "3. 請於 BN 放在 Input Layer 後，並比較結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Dropout, Activation\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 128, 32], dropout_rate= 0.2, pre_activate= False):\n",
    "    \n",
    "    #輸入層\n",
    "    input_layer= keras.layers.Input(input_shape)\n",
    "    \n",
    "    #隱藏層\n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x= keras.layers.Dense(units=n_units,                                  \n",
    "                                  name='hidden_layer'+str(i+1))(input_layer)\n",
    "            if pre_activate:\n",
    "                x= BatchNormalization()(x)\n",
    "                x= Activation(\"relu\")(x)\n",
    "            else:\n",
    "                x= Activation(\"relu\")(x)\n",
    "                x= BatchNormalization()(x)\n",
    "                \n",
    "        else:\n",
    "            x= keras.layers.Dense(units=n_units,\n",
    "                                  name='hidden_layer'+str(i+1))(x)\n",
    "            if pre_activate:\n",
    "                x= BatchNormalization()(x)\n",
    "                x= Activation(\"relu\")(x)\n",
    "            else:\n",
    "                x= Activation(\"relu\")(x)\n",
    "                x= BatchNormalization()(x)\n",
    "    \n",
    "    #輸出層\n",
    "    output_layer= keras.layers.Dense(units=output_units,\n",
    "                                     activation='softmax',\n",
    "                                     name='output_layer')(x)\n",
    "    \n",
    "    #建模\n",
    "    model= keras.models.Model(inputs=[input_layer],outputs=[output_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_Rate= 1e-3\n",
    "Epochs= 50\n",
    "Batch_size= [2, 16, 32, 128, 256] \n",
    "pre_activate= [True, False]\n",
    "Momentum= 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, preact: True, batch_size: 2\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,646,186\n",
      "Trainable params: 1,644,842\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      " - 153s - loss: 2.2557 - accuracy: 0.1550 - val_loss: 2.1710 - val_accuracy: 0.2094\n",
      "Epoch 2/50\n",
      " - 154s - loss: 2.2227 - accuracy: 0.1728 - val_loss: 2.1711 - val_accuracy: 0.2031\n",
      "Epoch 3/50\n",
      " - 158s - loss: 2.2219 - accuracy: 0.1727 - val_loss: 2.1509 - val_accuracy: 0.2208\n",
      "Epoch 4/50\n",
      " - 158s - loss: 2.2156 - accuracy: 0.1785 - val_loss: 2.1286 - val_accuracy: 0.2334\n",
      "Epoch 5/50\n",
      " - 157s - loss: 2.2117 - accuracy: 0.1783 - val_loss: 2.1207 - val_accuracy: 0.2214\n",
      "Epoch 6/50\n",
      " - 150s - loss: 2.2113 - accuracy: 0.1783 - val_loss: 2.1348 - val_accuracy: 0.2186\n",
      "Epoch 7/50\n",
      " - 150s - loss: 2.2136 - accuracy: 0.1805 - val_loss: 2.1279 - val_accuracy: 0.2237\n",
      "Epoch 8/50\n",
      " - 150s - loss: 2.2086 - accuracy: 0.1791 - val_loss: 2.1116 - val_accuracy: 0.2201\n",
      "Epoch 9/50\n",
      " - 151s - loss: 2.2010 - accuracy: 0.1830 - val_loss: 2.1312 - val_accuracy: 0.1958\n",
      "Epoch 10/50\n",
      " - 150s - loss: 2.2088 - accuracy: 0.1776 - val_loss: 2.1264 - val_accuracy: 0.1928\n",
      "Epoch 11/50\n",
      " - 151s - loss: 2.2088 - accuracy: 0.1791 - val_loss: 2.1389 - val_accuracy: 0.1938\n",
      "Epoch 12/50\n",
      " - 151s - loss: 2.2104 - accuracy: 0.1804 - val_loss: 2.1296 - val_accuracy: 0.2109\n",
      "Epoch 13/50\n",
      " - 151s - loss: 2.2019 - accuracy: 0.1829 - val_loss: 2.1445 - val_accuracy: 0.1898\n",
      "Epoch 14/50\n",
      " - 151s - loss: 2.1994 - accuracy: 0.1856 - val_loss: 2.0972 - val_accuracy: 0.2226\n",
      "Epoch 15/50\n",
      " - 151s - loss: 2.2006 - accuracy: 0.1835 - val_loss: 2.1161 - val_accuracy: 0.2154\n",
      "Epoch 16/50\n",
      " - 151s - loss: 2.2034 - accuracy: 0.1831 - val_loss: 2.1168 - val_accuracy: 0.2079\n",
      "Epoch 17/50\n",
      " - 151s - loss: 2.2055 - accuracy: 0.1818 - val_loss: 2.1405 - val_accuracy: 0.2137\n",
      "Epoch 18/50\n",
      " - 152s - loss: 2.2070 - accuracy: 0.1819 - val_loss: 2.1440 - val_accuracy: 0.1925\n",
      "Epoch 19/50\n",
      " - 152s - loss: 2.2033 - accuracy: 0.1817 - val_loss: 2.1344 - val_accuracy: 0.2073\n",
      "Epoch 20/50\n",
      " - 152s - loss: 2.2004 - accuracy: 0.1819 - val_loss: 2.1097 - val_accuracy: 0.2060\n",
      "Epoch 21/50\n",
      " - 153s - loss: 2.2032 - accuracy: 0.1833 - val_loss: 2.1355 - val_accuracy: 0.1948\n",
      "Epoch 22/50\n",
      " - 153s - loss: 2.2066 - accuracy: 0.1806 - val_loss: 2.1492 - val_accuracy: 0.1762\n",
      "Epoch 23/50\n",
      " - 154s - loss: 2.2029 - accuracy: 0.1829 - val_loss: 2.1102 - val_accuracy: 0.2010\n",
      "Epoch 24/50\n",
      " - 159s - loss: 2.2139 - accuracy: 0.1750 - val_loss: 2.1331 - val_accuracy: 0.2025\n",
      "Epoch 25/50\n",
      " - 160s - loss: 2.2101 - accuracy: 0.1797 - val_loss: 2.1504 - val_accuracy: 0.1907\n",
      "Epoch 26/50\n",
      " - 159s - loss: 2.2131 - accuracy: 0.1812 - val_loss: 2.1661 - val_accuracy: 0.1806\n",
      "Epoch 27/50\n",
      " - 160s - loss: 2.2169 - accuracy: 0.1764 - val_loss: 2.1546 - val_accuracy: 0.1861\n",
      "Epoch 28/50\n",
      " - 161s - loss: 2.2072 - accuracy: 0.1787 - val_loss: 2.1767 - val_accuracy: 0.1740\n",
      "Epoch 29/50\n",
      " - 159s - loss: 2.2068 - accuracy: 0.1841 - val_loss: 2.1700 - val_accuracy: 0.1768\n",
      "Epoch 30/50\n",
      " - 161s - loss: 2.2032 - accuracy: 0.1821 - val_loss: 2.1579 - val_accuracy: 0.1991\n",
      "Epoch 31/50\n",
      " - 159s - loss: 2.2158 - accuracy: 0.1760 - val_loss: 2.1490 - val_accuracy: 0.1930\n",
      "Epoch 32/50\n",
      " - 164s - loss: 2.2076 - accuracy: 0.1791 - val_loss: 2.1743 - val_accuracy: 0.1775\n",
      "Epoch 33/50\n",
      " - 167s - loss: 2.2087 - accuracy: 0.1838 - val_loss: 2.1588 - val_accuracy: 0.1902\n",
      "Epoch 34/50\n",
      " - 162s - loss: 2.2114 - accuracy: 0.1819 - val_loss: 2.1575 - val_accuracy: 0.1866\n",
      "Epoch 35/50\n",
      " - 161s - loss: 2.2073 - accuracy: 0.1799 - val_loss: 2.1659 - val_accuracy: 0.1839\n",
      "Epoch 36/50\n",
      " - 162s - loss: 2.2046 - accuracy: 0.1805 - val_loss: 2.1882 - val_accuracy: 0.1710\n",
      "Epoch 37/50\n",
      " - 158s - loss: 2.2074 - accuracy: 0.1820 - val_loss: 2.1632 - val_accuracy: 0.1804\n",
      "Epoch 38/50\n",
      " - 157s - loss: 2.2128 - accuracy: 0.1847 - val_loss: 2.1719 - val_accuracy: 0.1818\n",
      "Epoch 39/50\n",
      " - 156s - loss: 2.2067 - accuracy: 0.1890 - val_loss: 2.1300 - val_accuracy: 0.2045\n",
      "Epoch 40/50\n",
      " - 154s - loss: 2.2021 - accuracy: 0.1898 - val_loss: 2.1344 - val_accuracy: 0.2154\n",
      "Epoch 41/50\n",
      " - 152s - loss: 2.2016 - accuracy: 0.1916 - val_loss: 2.1584 - val_accuracy: 0.2084\n",
      "Epoch 42/50\n",
      " - 152s - loss: 2.2048 - accuracy: 0.1869 - val_loss: 2.1665 - val_accuracy: 0.1893\n",
      "Epoch 43/50\n",
      " - 152s - loss: 2.2051 - accuracy: 0.1883 - val_loss: 2.1671 - val_accuracy: 0.2103\n",
      "Epoch 44/50\n",
      " - 152s - loss: 2.2087 - accuracy: 0.1801 - val_loss: 2.1562 - val_accuracy: 0.2024\n",
      "Epoch 45/50\n",
      " - 153s - loss: 2.2060 - accuracy: 0.1882 - val_loss: 2.1486 - val_accuracy: 0.1964\n",
      "Epoch 46/50\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i, (preact, Bs) in enumerate(itertools.product(pre_activate, Batch_size)):\n",
    "    print(\"Numbers of exp: %i, preact: %s, batch_size: %i\" % (i, preact, Bs))\n",
    "    model = build_mlp(input_shape= x_train.shape[1:], pre_activate= preact)\n",
    "    model.summary()\n",
    "    opt= keras.optimizers.Adam(lr= Learning_Rate)\n",
    "    model.compile(loss= 'categorical_crossentropy', metrics=['accuracy'], optimizer= opt)\n",
    "    model.fit(x_train, y_train,\n",
    "              epochs= Epochs,\n",
    "              batch_size= Bs,\n",
    "              validation_data= (x_test, y_test),\n",
    "              verbose= 2,\n",
    "              shuffle= True)\n",
    "    #collecting data\n",
    "    name_tag = ('exp-%s-pre-%s-batch_size-%s' % (str(i), str(preact), str(Bs)))\n",
    "    results[name_tag]= {'train_loss':model.history.history['loss'],\n",
    "                        'valid_loss':model.history.history['val_loss'],\n",
    "                        'train_acc':model.history.history['accuracy'],\n",
    "                        'valid_acc':model.history.history['val_accuracy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "#Rainbow_line\n",
    "num_colors= len(results.keys())\n",
    "cm= plt.getcmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=num_colors-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(num_colors)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train_loss'])),results[cond]['train_loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid_loss'])),results[cond]['valid_loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train_acc'])),results[cond]['train_acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid_acc'])),results[cond]['valid_acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
