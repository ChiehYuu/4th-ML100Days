{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業目標]\n",
    "持續接觸有關機器學習的相關專案與最新技術"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "透過觀察頂尖公司的機器學習文章，來了解各公司是怎麼應用機器學習在實際的專案上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業]\n",
    "今天的作業希望大家能夠看看全球機器學習巨頭們在做的機器學習專案。以 google 為例，下圖是 Google 內部專案使用機器學習的數量，隨著時間進展，現在早已超過 2000 個專案在使用機器學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*U_L8qI8RmYS-MOBrYvXhSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下幫同學整理幾間知名企業的 blog 或機器學習網站 (自行搜尋也可)，這些網站都會整理最新的機器學習專案或者是技術文章，請挑選一篇文章閱讀並試著回答\n",
    "1. 專案的目標？ (要解決什麼問題）\n",
    "2. 使用的技術是？ (只需知道名稱即可，例如：使用 CNN 卷積神經網路做影像分類)\n",
    "3. 資料來源？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Google AI blog](https://ai.googleblog.com/)\n",
    "- [Facebook Research blog](https://research.fb.com/blog/)\n",
    "- [Apple machine learning journal](https://machinelearning.apple.com/)\n",
    "- [機器之心](https://www.jiqizhixin.com/)\n",
    "- [雷鋒網](http://www.leiphone.com/category/ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Title :  Can You Trust Your Model’s Uncertainty?\n",
    " \n",
    "    - 藉由不定性外在基準如：不同資料形態，增加醫學工程上covariate shift之可信度與可靠度並藉由不同方法找到最佳且最低干擾的平移模式\n",
    "   \n",
    " 2. 使用方法有以下六種:\n",
    " \n",
    "    1. Vanilla: Maximum-likelihood DNN.\n",
    "    2. Temperature Scaling: Vanilla model calibrated on in-distribution as described in Guo et al. 2017\n",
    "    3. Ensemble of vanilla models as described in Lakshminarayanan et al. 2017\n",
    "    4. Dropout: MC Dropout as described by Gal & Ghahramani\n",
    "    5. SVI: Mean field BNN optimized by stochastic variational inference.\n",
    "    6. LL-Dropout and LL-SVI: Simplified variants of Dropout and SVI where the method is only applied to the last layer.\n",
    "   \n",
    " 3. 資料來源有以下五種：\n",
    " \n",
    "    1. MNIST and rotated MNIST.\n",
    "    2. CIFAR-10 with corruptions by Hendrycks & Dietterich 2019\n",
    "    3. ImageNet 2012 with corruptions by Hendrycks & Dietterich 2019\n",
    "    4. Criteo's ad-click prediction dataset with synthetic random feature corruptions.\n",
    "    5. 20 Newsgroups text with out-of-distribution data from LM1B."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
